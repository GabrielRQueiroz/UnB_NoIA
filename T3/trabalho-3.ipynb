{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autores: \n",
    "**Gabriel Roberto (221020870) e Jean Soares (241033810)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "Ry2z464bZy05"
   },
   "outputs": [],
   "source": [
    "from d2l import tensorflow as d2l\n",
    "import requests\n",
    "import tarfile\n",
    "import re\n",
    "import collections\n",
    "import pandas as pd\n",
    "from nltk.translate import IBMModel1\n",
    "from nltk.translate.bleu_score import sentence_bleu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "W3cj4W4WZ_YO"
   },
   "outputs": [],
   "source": [
    "def baixar_arquivo(url, endereco):\n",
    "    resposta = requests.get(url)\n",
    "    if resposta.status_code == requests.codes.OK:\n",
    "        with open(endereco, 'wb') as novo_arquivo:\n",
    "                novo_arquivo.write(resposta.content)\n",
    "        print(\"Download finalizado. Arquivo salvo em: {}\".format(endereco))\n",
    "    else:\n",
    "        resposta.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nwxw1RJIaFA0",
    "outputId": "c151e501-828b-44c0-ca1b-8963679911bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download finalizado. Arquivo salvo em: ./raw_dataset.tgz\n"
     ]
    }
   ],
   "source": [
    "URL_arquivo = 'https://www.statmt.org/europarl/v7/pt-en.tgz'\n",
    "\n",
    "baixar_arquivo(URL_arquivo, './raw_dataset.tgz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LqDFNIf6aJ-r",
    "outputId": "bdd7b0d9-f2ea-49cd-99ab-ad159119603f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "europarl-v7.pt-en.en\n",
      "europarl-v7.pt-en.pt\n"
     ]
    }
   ],
   "source": [
    "# Caminho para o arquivo .tgz\n",
    "caminho_arquivo = './raw_dataset.tgz'\n",
    "\n",
    "# Abrir o arquivo .tgz\n",
    "with tarfile.open(caminho_arquivo, 'r:gz') as arquivo_tgz:\n",
    "    # Extrair todos os arquivos do .tgz\n",
    "    arquivo_tgz.extractall(path='./')\n",
    "\n",
    "    # Listar os arquivos extraídos\n",
    "    for membro in arquivo_tgz.getmembers():\n",
    "        print(membro.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leitura do Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "BUZ7z-oBanHx"
   },
   "outputs": [],
   "source": [
    "class ParallelCorpus(d2l.DataModule):\n",
    "    \"\"\"The Parallel Corpus Portuguese-English dataset.\"\"\"\n",
    "    def _download(self, fname):\n",
    "        with open(fname, encoding=\"utf-8\") as f:\n",
    "            return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "aJ5vItAYfhUx",
    "outputId": "8cf0fcf7-d7db-4232-b268-8e8529a3ef6e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Resumption of the session\\nI declare resumed the session of t'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = ParallelCorpus()\n",
    "raw_text_en = data._download('./europarl-v7.pt-en.en')\n",
    "raw_text_en[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "OP-iwcHLfrYJ",
    "outputId": "7fb5cc82-efc4-4f8e-bd4b-a166f27db6dc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Reinício da sessão\\nDeclaro reaberta a sessão do Parlamento E'"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_text_pt = data._download('./europarl-v7.pt-en.pt')\n",
    "raw_text_pt[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "DHM_zy_Lapb9"
   },
   "outputs": [],
   "source": [
    "@d2l.add_to_class(ParallelCorpus)\n",
    "def _preprocess(self, text):\n",
    "    return re.sub(r'[^\\w\\s]', '', text).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Dl6t6Yeuf5Vq",
    "outputId": "31e1acec-6d63-4624-89cb-6e45fe586bf8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'resumption of the session i declare resumed the session of t'"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo dez mil senteças para facilitar o processamento\n",
    "text_en = data._preprocess(\" \".join(raw_text_en.split()[:10000]))\n",
    "\n",
    "text_en[:60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "bDSzo-r8gGsy",
    "outputId": "ca4da050-0676-4f50-bb8e-0c9409ca973f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reinício da sessão declaro reaberta a sessão do parlamento e'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removendo dez mil senteça para facilitar o processamento\n",
    "text_pt = data._preprocess(' '.join(raw_text_pt.split()[:10000]))\n",
    "\n",
    "text_pt[:60]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VQHyS5ZRF9gY",
    "outputId": "d7196346-7d9e-4261-8e96-a4f8c27f4365"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9956 9954\n"
     ]
    }
   ],
   "source": [
    "source_sentences = text_en.split()\n",
    "target_sentences = text_pt.split()\n",
    "\n",
    "print(len(source_sentences), len(target_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "id": "60cWnkr5GXbu"
   },
   "outputs": [],
   "source": [
    "def preprocess2(text):\n",
    "  return re.sub(r'[^a-z]+', ' ', text).split()\n",
    "\n",
    "def get_diff_words(text):\n",
    "  set_words = set()\n",
    "  text_list = preprocess2(text)\n",
    "\n",
    "  for word in text_list:\n",
    "    set_words.add(word)\n",
    "\n",
    "  return set_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "id": "sRBC9dmMINFX",
    "outputId": "a9f6b87c-b140-407a-ef3c-339f71834ff4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contribute',\n",
       " 'greater',\n",
       " 'lament',\n",
       " 'further',\n",
       " 'tabled',\n",
       " 'population',\n",
       " 'details',\n",
       " 'high',\n",
       " 'the',\n",
       " 'value',\n",
       " 'councils',\n",
       " 'millennium',\n",
       " 'nations',\n",
       " 'home',\n",
       " 'use',\n",
       " 'wording',\n",
       " 'acceptable',\n",
       " 'finding',\n",
       " 'sectors',\n",
       " 'limit',\n",
       " 'introduced',\n",
       " 'request',\n",
       " 'issues',\n",
       " 'courts',\n",
       " 'most',\n",
       " 'item',\n",
       " 'provides',\n",
       " 'looking',\n",
       " 'colleges',\n",
       " 'applause',\n",
       " 'happy',\n",
       " 'quaestors',\n",
       " 'zimeray',\n",
       " 'document',\n",
       " 'paragraph',\n",
       " 'seeking',\n",
       " 'agenda',\n",
       " 'hell',\n",
       " 'transitional',\n",
       " 'attend',\n",
       " 'say',\n",
       " 'spent',\n",
       " 'shown',\n",
       " 'amount',\n",
       " 'card',\n",
       " 'perceive',\n",
       " 'considerably',\n",
       " 'amendment',\n",
       " 'eyes',\n",
       " 'demographic',\n",
       " 'regional',\n",
       " 'execution',\n",
       " 'period',\n",
       " 'be',\n",
       " 'portuguese',\n",
       " 'intended',\n",
       " 'retained',\n",
       " 'outcome',\n",
       " 'whom',\n",
       " 'conferred',\n",
       " 'fields',\n",
       " 'whole',\n",
       " 'abc',\n",
       " 'responsibility',\n",
       " 'ec',\n",
       " 'seem',\n",
       " 'press',\n",
       " 'problem',\n",
       " 'regulatory',\n",
       " 'believes',\n",
       " 'partially',\n",
       " 'sealing',\n",
       " 'indicated',\n",
       " 'explanations',\n",
       " 'increased',\n",
       " 'financially',\n",
       " 'begin',\n",
       " 'unnecessary',\n",
       " 'propose',\n",
       " 'somewhat',\n",
       " 'leave',\n",
       " 'resulting',\n",
       " 'fundamental',\n",
       " 'carried',\n",
       " 'forefront',\n",
       " 'effort',\n",
       " 'unanimous',\n",
       " 'quota',\n",
       " 'discussed',\n",
       " 'lanka',\n",
       " 'variations',\n",
       " 'final',\n",
       " 'moor',\n",
       " 'terribly',\n",
       " 'indepth',\n",
       " 'have',\n",
       " 'someone',\n",
       " 'forward',\n",
       " 'simply',\n",
       " 'appropriate',\n",
       " 'fleet',\n",
       " 'simpson',\n",
       " 'meant',\n",
       " 'finer',\n",
       " 'killings',\n",
       " 'interest',\n",
       " 'ours',\n",
       " 'thanks',\n",
       " 'accidents',\n",
       " 'owing',\n",
       " 'thing',\n",
       " 'welcome',\n",
       " 'complex',\n",
       " 'barents',\n",
       " 'wider',\n",
       " 'up',\n",
       " 'granted',\n",
       " 'per',\n",
       " 'exceptionally',\n",
       " 'namely',\n",
       " 'networks',\n",
       " 'make',\n",
       " 'any',\n",
       " 'chairman',\n",
       " 'introducing',\n",
       " 'agreed',\n",
       " 'private',\n",
       " 'referred',\n",
       " 'discontent',\n",
       " 'building',\n",
       " 'avalanche',\n",
       " 'strategic',\n",
       " 'citizens',\n",
       " 'advise',\n",
       " 'your',\n",
       " 'extremely',\n",
       " 'through',\n",
       " 'expenditure',\n",
       " 'ignorance',\n",
       " 'work',\n",
       " 'generally',\n",
       " 'capital',\n",
       " 'explanation',\n",
       " 'bureaucracy',\n",
       " 'criteria',\n",
       " 'voting',\n",
       " 'brief',\n",
       " 'omission',\n",
       " 'alexander',\n",
       " 'transparent',\n",
       " 'tobin',\n",
       " 'uniform',\n",
       " 'itself',\n",
       " 'admit',\n",
       " 'one',\n",
       " 'known',\n",
       " 'against',\n",
       " 'policy',\n",
       " 'however',\n",
       " 'consider',\n",
       " 'route',\n",
       " 'parliamentary',\n",
       " 'logical',\n",
       " 'gladly',\n",
       " 'substantial',\n",
       " 'matter',\n",
       " 'great',\n",
       " 'yes',\n",
       " 'initially',\n",
       " 'march',\n",
       " 'advanced',\n",
       " 'intervention',\n",
       " 'fight',\n",
       " 'dictates',\n",
       " 'existing',\n",
       " 'relate',\n",
       " 'justifying',\n",
       " 'doing',\n",
       " 'dates',\n",
       " 'discussion',\n",
       " 'i',\n",
       " 'ten',\n",
       " 'love',\n",
       " 'representations',\n",
       " 'dangerous',\n",
       " 'broaden',\n",
       " 'unilaterally',\n",
       " 'verification',\n",
       " 'arrangements',\n",
       " 'good',\n",
       " 'basically',\n",
       " 'nonagricultural',\n",
       " 'law',\n",
       " 'maintaining',\n",
       " 'test',\n",
       " 'entail',\n",
       " 'regret',\n",
       " 'resumed',\n",
       " 'perspective',\n",
       " 'additionality',\n",
       " 'series',\n",
       " 'before',\n",
       " 'rural',\n",
       " 'genuinely',\n",
       " 'plooijvan',\n",
       " 'opinion',\n",
       " 'includes',\n",
       " 'efforts',\n",
       " 'december',\n",
       " 'urge',\n",
       " 'deeply',\n",
       " 'n',\n",
       " 'lack',\n",
       " 'satisfactorily',\n",
       " 'hidden',\n",
       " 'represent',\n",
       " 'feeling',\n",
       " 'lynne',\n",
       " 'chairmanship',\n",
       " 'certainly',\n",
       " 'differentiating',\n",
       " 'fellow',\n",
       " 'vicepresident',\n",
       " 'eu',\n",
       " 'changeover',\n",
       " 'employees',\n",
       " 'brussels',\n",
       " 'acquis',\n",
       " 'communication',\n",
       " 'information',\n",
       " 'flexible',\n",
       " 'hypothesis',\n",
       " 'speech',\n",
       " 'confines',\n",
       " 'cunha',\n",
       " 'growing',\n",
       " 'guarantees',\n",
       " 'human',\n",
       " 'sense',\n",
       " 'targets',\n",
       " 'earlier',\n",
       " 'says',\n",
       " 'employment',\n",
       " 'having',\n",
       " 'back',\n",
       " 'surely',\n",
       " 'poverty',\n",
       " 'actually',\n",
       " 'ratings',\n",
       " 'exclusion',\n",
       " 'exclusive',\n",
       " 'sums',\n",
       " 'behaviour',\n",
       " 'reopen',\n",
       " 'explain',\n",
       " 'st',\n",
       " 'tunnels',\n",
       " 'exception',\n",
       " 'not',\n",
       " 'relation',\n",
       " 'maximum',\n",
       " 'coinciding',\n",
       " 'affected',\n",
       " 'business',\n",
       " 'its',\n",
       " 'unknown',\n",
       " 'mr',\n",
       " 'system',\n",
       " 'pillars',\n",
       " 'logic',\n",
       " 'sweden',\n",
       " 'conclusion',\n",
       " 'quickly',\n",
       " 'newspaper',\n",
       " 'technical',\n",
       " 'reestablish',\n",
       " 'territory',\n",
       " 'reference',\n",
       " 'welcomed',\n",
       " 'live',\n",
       " 'subsidiarity',\n",
       " 'materials',\n",
       " 'past',\n",
       " 'reflect',\n",
       " 'analysis',\n",
       " 'eighteen',\n",
       " 'urging',\n",
       " 'holding',\n",
       " 'bearing',\n",
       " 'iso',\n",
       " 'would',\n",
       " 'provider',\n",
       " 'recommend',\n",
       " 'sentenced',\n",
       " 'characterisations',\n",
       " 'subsequent',\n",
       " 'merely',\n",
       " 'achieve',\n",
       " 'rather',\n",
       " 'tax',\n",
       " 'fund',\n",
       " 'ready',\n",
       " 'transit',\n",
       " 'transition',\n",
       " 'negotiations',\n",
       " 'feel',\n",
       " 'all',\n",
       " 'enforcement',\n",
       " 'much',\n",
       " 'correct',\n",
       " 'enacting',\n",
       " 'b',\n",
       " 'acts',\n",
       " 'write',\n",
       " 'crespo',\n",
       " 'own',\n",
       " 'enforced',\n",
       " 'messrs',\n",
       " 'wednesday',\n",
       " 'international',\n",
       " 'reasons',\n",
       " 'provide',\n",
       " 'properly',\n",
       " 'sorry',\n",
       " 'initiatives',\n",
       " 'college',\n",
       " 'wholehearted',\n",
       " 'prerequisites',\n",
       " 'volatile',\n",
       " 'decide',\n",
       " 'obtaining',\n",
       " 'many',\n",
       " 'lorries',\n",
       " 'formulas',\n",
       " 'strategy',\n",
       " 'drive',\n",
       " 'hicks',\n",
       " 'vivid',\n",
       " 'educated',\n",
       " 'meeting',\n",
       " 'may',\n",
       " 'particular',\n",
       " 'does',\n",
       " 'union',\n",
       " 'cooperation',\n",
       " 'fail',\n",
       " 'decentralisation',\n",
       " 'stands',\n",
       " 'role',\n",
       " 'put',\n",
       " 'hold',\n",
       " 'assassinated',\n",
       " 'proposal',\n",
       " 'prodi',\n",
       " 'confused',\n",
       " 'violent',\n",
       " 'colleague',\n",
       " 'memory',\n",
       " 'safer',\n",
       " 'classification',\n",
       " 'nos',\n",
       " 'presently',\n",
       " 'advocating',\n",
       " 'health',\n",
       " 'several',\n",
       " 'minimum',\n",
       " 'rail',\n",
       " 'faces',\n",
       " 'under',\n",
       " 'belgium',\n",
       " 'stated',\n",
       " 'refusing',\n",
       " 'structural',\n",
       " 'familiar',\n",
       " 'renewables',\n",
       " 'petition',\n",
       " 'form',\n",
       " 'recall',\n",
       " 'hasten',\n",
       " 'significance',\n",
       " 'open',\n",
       " 'cards',\n",
       " 'dilatory',\n",
       " 'cost',\n",
       " 'rightly',\n",
       " 'letter',\n",
       " 'friday',\n",
       " 'countries',\n",
       " 'approved',\n",
       " 'inactivity',\n",
       " 'london',\n",
       " 'energy',\n",
       " 'schemes',\n",
       " 'first',\n",
       " 'truly',\n",
       " 'cargo',\n",
       " 'palacio',\n",
       " 'remains',\n",
       " 'am',\n",
       " 'bush',\n",
       " 'timetable',\n",
       " 'modest',\n",
       " 'applied',\n",
       " 'ghost',\n",
       " 'executed',\n",
       " 'tunnel',\n",
       " 'failed',\n",
       " 'materialise',\n",
       " 'lacks',\n",
       " 'sound',\n",
       " 'public',\n",
       " 'increasing',\n",
       " 'my',\n",
       " 'producers',\n",
       " 'above',\n",
       " 'motivated',\n",
       " 'nikitin',\n",
       " 'commissioner',\n",
       " 'objectives',\n",
       " 'irresponsible',\n",
       " 'h',\n",
       " 'endorsed',\n",
       " 'rich',\n",
       " 'pass',\n",
       " 'internal',\n",
       " 'excellent',\n",
       " 'linking',\n",
       " 'after',\n",
       " 'continued',\n",
       " 'wurtz',\n",
       " 'generated',\n",
       " 'industry',\n",
       " 'prior',\n",
       " 'appealing',\n",
       " 'remember',\n",
       " 'established',\n",
       " 'vote',\n",
       " 'organisation',\n",
       " 'wednesdays',\n",
       " 'condemned',\n",
       " 'develop',\n",
       " 'nature',\n",
       " 'view',\n",
       " 'dealt',\n",
       " 'north',\n",
       " 'myself',\n",
       " 'seattle',\n",
       " 'coup',\n",
       " 'victims',\n",
       " 'appeared',\n",
       " 'ladies',\n",
       " 'projects',\n",
       " 'small',\n",
       " 'proceeding',\n",
       " 'keen',\n",
       " 'examined',\n",
       " 'structures',\n",
       " 'findings',\n",
       " 'comments',\n",
       " 'adjourned',\n",
       " 'quality',\n",
       " 'they',\n",
       " 'ponnambalam',\n",
       " 'connected',\n",
       " 'speaking',\n",
       " 'denied',\n",
       " 'right',\n",
       " 'bear',\n",
       " 'comment',\n",
       " 'whatever',\n",
       " 'case',\n",
       " 'solution',\n",
       " 'who',\n",
       " 'lower',\n",
       " 'rose',\n",
       " 'objective',\n",
       " 'viewed',\n",
       " 'reservations',\n",
       " 'nonetheless',\n",
       " 'serious',\n",
       " 'context',\n",
       " 'now',\n",
       " 'crashes',\n",
       " 'examine',\n",
       " 'expected',\n",
       " 'text',\n",
       " 'explosions',\n",
       " 'pleased',\n",
       " 'respect',\n",
       " 'soon',\n",
       " 'carrying',\n",
       " 'ensure',\n",
       " 'unquestionably',\n",
       " 'linked',\n",
       " 'concluded',\n",
       " 'improved',\n",
       " 'counted',\n",
       " 'improving',\n",
       " 'contribution',\n",
       " 'wide',\n",
       " 'protect',\n",
       " 'spoke',\n",
       " 'coordination',\n",
       " 'confidence',\n",
       " 'lankan',\n",
       " 'person',\n",
       " 'italy',\n",
       " 'once',\n",
       " 'safety',\n",
       " 'too',\n",
       " 'process',\n",
       " 'despite',\n",
       " 'shutting',\n",
       " 'different',\n",
       " 'means',\n",
       " 'necessary',\n",
       " 'furthermore',\n",
       " 'imply',\n",
       " 'recommended',\n",
       " 'crespos',\n",
       " 'end',\n",
       " 'nonattached',\n",
       " 'equilibrium',\n",
       " 'whatsoever',\n",
       " 'years',\n",
       " 'issue',\n",
       " 'laughter',\n",
       " 'me',\n",
       " 'meantime',\n",
       " 'recitals',\n",
       " 'affect',\n",
       " 'strengthen',\n",
       " 'result',\n",
       " 'ago',\n",
       " 'koch',\n",
       " 'record',\n",
       " 'sufficient',\n",
       " 'look',\n",
       " 'response',\n",
       " 'key',\n",
       " 'specifics',\n",
       " 'clearly',\n",
       " 'simple',\n",
       " 'floor',\n",
       " 'debated',\n",
       " 'listen',\n",
       " 'sitting',\n",
       " 'organisations',\n",
       " 'additional',\n",
       " 'compulsory',\n",
       " 'pulled',\n",
       " 'debating',\n",
       " 'drivers',\n",
       " 'de',\n",
       " 'differently',\n",
       " 'frostresistance',\n",
       " 'internet',\n",
       " 'expeditiously',\n",
       " 'want',\n",
       " 'competitive',\n",
       " 'why',\n",
       " 'patience',\n",
       " 'needing',\n",
       " 'get',\n",
       " 'northern',\n",
       " 'farm',\n",
       " 'changes',\n",
       " 'rejected',\n",
       " 'economic',\n",
       " 'order',\n",
       " 'time',\n",
       " 'regarding',\n",
       " 'french',\n",
       " 'continue',\n",
       " 'challenge',\n",
       " 'though',\n",
       " 'done',\n",
       " 'them',\n",
       " 'standards',\n",
       " 'available',\n",
       " 'appear',\n",
       " 'running',\n",
       " 'commission',\n",
       " 'so',\n",
       " 'he',\n",
       " 'allow',\n",
       " 'accurate',\n",
       " 'industrial',\n",
       " 'how',\n",
       " 'creation',\n",
       " 'cooperate',\n",
       " 'plan',\n",
       " 'gap',\n",
       " 'types',\n",
       " 'offer',\n",
       " 'fuster',\n",
       " 'ever',\n",
       " 'workers',\n",
       " 'major',\n",
       " 'century',\n",
       " 'needless',\n",
       " 'sources',\n",
       " 'young',\n",
       " 'provisions',\n",
       " 'inadmissible',\n",
       " 'drew',\n",
       " 'superb',\n",
       " 'paradoxical',\n",
       " 'anything',\n",
       " 'some',\n",
       " 'thank',\n",
       " 'stop',\n",
       " 'suggested',\n",
       " 'speak',\n",
       " 'afterwards',\n",
       " 'adjacent',\n",
       " 'analyses',\n",
       " 'suggests',\n",
       " 'guidelines',\n",
       " 'inaugural',\n",
       " 'occurred',\n",
       " 'consists',\n",
       " 'huge',\n",
       " 'astonished',\n",
       " 'allowed',\n",
       " 'each',\n",
       " 'delays',\n",
       " 'diverted',\n",
       " 'frequently',\n",
       " 'us',\n",
       " 'eastern',\n",
       " 'damaging',\n",
       " 'thesis',\n",
       " 'knowing',\n",
       " 'constructive',\n",
       " 'date',\n",
       " 'vast',\n",
       " 'imagine',\n",
       " 'amending',\n",
       " 'heritage',\n",
       " 'concerning',\n",
       " 'ourselves',\n",
       " 'easier',\n",
       " 'about',\n",
       " 'used',\n",
       " 'way',\n",
       " 'advice',\n",
       " 'parliaments',\n",
       " 'light',\n",
       " 'review',\n",
       " 'delay',\n",
       " 'pity',\n",
       " 'bar',\n",
       " 'never',\n",
       " 'disasters',\n",
       " 'topical',\n",
       " 'establishing',\n",
       " 'community',\n",
       " 'multiannual',\n",
       " 'reconsider',\n",
       " 'usual',\n",
       " 'labour',\n",
       " 'presentation',\n",
       " 'quick',\n",
       " 'hope',\n",
       " 'undeveloped',\n",
       " 'european',\n",
       " 'planning',\n",
       " 'adopting',\n",
       " 'reason',\n",
       " 'funding',\n",
       " 'matters',\n",
       " 'refuse',\n",
       " 'accept',\n",
       " 'establishment',\n",
       " 'like',\n",
       " 'longer',\n",
       " 'present',\n",
       " 'amended',\n",
       " 'waterway',\n",
       " 'resolve',\n",
       " 'accident',\n",
       " 'vehicles',\n",
       " 'few',\n",
       " 'conference',\n",
       " 'communautaire',\n",
       " 'apply',\n",
       " 'concerns',\n",
       " 'given',\n",
       " 'passes',\n",
       " 'degree',\n",
       " 'reminded',\n",
       " 'expressed',\n",
       " 'rapporteur',\n",
       " 'minute',\n",
       " 'exciting',\n",
       " 'purely',\n",
       " 'status',\n",
       " 'subsequently',\n",
       " 'laws',\n",
       " 'better',\n",
       " 'finnish',\n",
       " 'voted',\n",
       " 'field',\n",
       " 'competently',\n",
       " 'pay',\n",
       " 'embargo',\n",
       " 'lives',\n",
       " 'this',\n",
       " 'recent',\n",
       " 'prevention',\n",
       " 'together',\n",
       " 'man',\n",
       " 'common',\n",
       " 'ratify',\n",
       " 'road',\n",
       " 'worth',\n",
       " 'fit',\n",
       " 'idea',\n",
       " 'quarters',\n",
       " 'administrative',\n",
       " 'flautre',\n",
       " 'do',\n",
       " 'commissions',\n",
       " 'socialist',\n",
       " 'monday',\n",
       " 'down',\n",
       " 'affairs',\n",
       " 'various',\n",
       " 'berenguer',\n",
       " 'margins',\n",
       " 'met',\n",
       " 'approximation',\n",
       " 'perhaps',\n",
       " 'speaker',\n",
       " 'job',\n",
       " 'worse',\n",
       " 'requests',\n",
       " 'cannot',\n",
       " 'quantities',\n",
       " 'take',\n",
       " 'body',\n",
       " 'minutes',\n",
       " 'is',\n",
       " 'ill',\n",
       " 'representing',\n",
       " 'activity',\n",
       " 'ez',\n",
       " 'treaties',\n",
       " 'poettering',\n",
       " 'withdrawn',\n",
       " 'tanks',\n",
       " 'indicates',\n",
       " 'storms',\n",
       " 'alleviate',\n",
       " 'resumption',\n",
       " 'week',\n",
       " 'sri',\n",
       " 'therefore',\n",
       " 'cox',\n",
       " 'applausethe',\n",
       " 'in',\n",
       " 'harmonising',\n",
       " 'institutions',\n",
       " 'message',\n",
       " 'willingness',\n",
       " 'latest',\n",
       " 'then',\n",
       " 'basis',\n",
       " 'taking',\n",
       " 'discuss',\n",
       " 'packaging',\n",
       " 'restructuring',\n",
       " 'burden',\n",
       " 'tread',\n",
       " 'year',\n",
       " 'prosecutor',\n",
       " 'although',\n",
       " 'either',\n",
       " 'businesses',\n",
       " 'effect',\n",
       " 'possible',\n",
       " 'bit',\n",
       " 'sufficiently',\n",
       " 'useful',\n",
       " 'accepted',\n",
       " 'plenary',\n",
       " 'unable',\n",
       " 'multifunctional',\n",
       " 'nuisance',\n",
       " 'monopoly',\n",
       " 'south',\n",
       " 'possibly',\n",
       " 'unfavourable',\n",
       " 'discussing',\n",
       " 'risk',\n",
       " 'sign',\n",
       " 'approving',\n",
       " 'express',\n",
       " 'erika',\n",
       " 'alone',\n",
       " 'just',\n",
       " 'without',\n",
       " 'using',\n",
       " 'supervisory',\n",
       " 'by',\n",
       " 'enough',\n",
       " 'interventions',\n",
       " 'liked',\n",
       " 'congratulate',\n",
       " 'advertising',\n",
       " 'texts',\n",
       " 'scale',\n",
       " 'include',\n",
       " 'locating',\n",
       " 'service',\n",
       " 'an',\n",
       " 'channels',\n",
       " 'justification',\n",
       " 'signed',\n",
       " 'sometimes',\n",
       " 'initiative',\n",
       " 'consequences',\n",
       " 'included',\n",
       " 'cut',\n",
       " 'fall',\n",
       " 'fact',\n",
       " 'protecting',\n",
       " 'comes',\n",
       " 'universities',\n",
       " 'japan',\n",
       " 'desperately',\n",
       " 'penalties',\n",
       " 'moves',\n",
       " 'inspire',\n",
       " 'funds',\n",
       " 'refer',\n",
       " 'environment',\n",
       " 'add',\n",
       " 'market',\n",
       " 'finland',\n",
       " 'risks',\n",
       " 'been',\n",
       " 'hearing',\n",
       " 'third',\n",
       " 'services',\n",
       " 'requesting',\n",
       " 'europes',\n",
       " 'wrong',\n",
       " 'particularly',\n",
       " 'dared',\n",
       " 'february',\n",
       " 'play',\n",
       " 'directive',\n",
       " 'agree',\n",
       " 'evans',\n",
       " 'beyond',\n",
       " 'there',\n",
       " 'might',\n",
       " 'legally',\n",
       " 'company',\n",
       " 'enactment',\n",
       " 'completion',\n",
       " 'railways',\n",
       " 'start',\n",
       " 'getting',\n",
       " 'obvious',\n",
       " 'national',\n",
       " 'oral',\n",
       " 'pretext',\n",
       " 'stretched',\n",
       " 'rating',\n",
       " 'mandate',\n",
       " 'brittany',\n",
       " 'originally',\n",
       " 'writing',\n",
       " 'impose',\n",
       " 'transparency',\n",
       " 'relates',\n",
       " 'amongst',\n",
       " 'will',\n",
       " 'emphasised',\n",
       " 'kilos',\n",
       " 'required',\n",
       " 'must',\n",
       " 'ensures',\n",
       " 'setting',\n",
       " 'outside',\n",
       " 'renovation',\n",
       " 'governor',\n",
       " 'commitment',\n",
       " 'external',\n",
       " 'agriculture',\n",
       " 'finally',\n",
       " 'austria',\n",
       " 'stage',\n",
       " 'led',\n",
       " 'flexibility',\n",
       " 'tauern',\n",
       " 'environmental',\n",
       " 'relating',\n",
       " 'afresh',\n",
       " 'only',\n",
       " 'exploiting',\n",
       " 'asking',\n",
       " 'providing',\n",
       " 'livelihood',\n",
       " 'supported',\n",
       " 'something',\n",
       " 'reform',\n",
       " 'uncertainty',\n",
       " 'prestigious',\n",
       " 'otherwise',\n",
       " 'eldr',\n",
       " 'rejects',\n",
       " 'advance',\n",
       " 'speakers',\n",
       " 'prolongs',\n",
       " 'defined',\n",
       " 'volume',\n",
       " 'reprieve',\n",
       " 'commerce',\n",
       " 'uk',\n",
       " 'disintegration',\n",
       " 'poor',\n",
       " 'support',\n",
       " 'level',\n",
       " 'disappearing',\n",
       " 'compliment',\n",
       " 'next',\n",
       " 'basic',\n",
       " 'nosmoking',\n",
       " 'drill',\n",
       " 'previously',\n",
       " 'com',\n",
       " 'indonesia',\n",
       " 'foggy',\n",
       " 'state',\n",
       " 'enforcing',\n",
       " 'inadmissibility',\n",
       " 'fire',\n",
       " 'increase',\n",
       " 'afford',\n",
       " 'proper',\n",
       " 'province',\n",
       " 'guidance',\n",
       " 'fully',\n",
       " 'lot',\n",
       " 'his',\n",
       " 'impetus',\n",
       " 'peaceful',\n",
       " 'agrees',\n",
       " 'exacerbates',\n",
       " 'exclusively',\n",
       " 'jobs',\n",
       " 'dutch',\n",
       " 'principality',\n",
       " 'monies',\n",
       " 'resolutions',\n",
       " 'prepare',\n",
       " 'romano',\n",
       " 'appreciation',\n",
       " 'worded',\n",
       " 'was',\n",
       " 'paid',\n",
       " 'feasible',\n",
       " 'ports',\n",
       " 'inadequate',\n",
       " 'working',\n",
       " 'worst',\n",
       " 'disgraceful',\n",
       " 'pointed',\n",
       " 'cases',\n",
       " 'previous',\n",
       " 'alternatively',\n",
       " 'america',\n",
       " 'safe',\n",
       " 'preserving',\n",
       " 'on',\n",
       " 'longterm',\n",
       " 'opportunities',\n",
       " 'addressed',\n",
       " 'proposals',\n",
       " 'ships',\n",
       " 'followed',\n",
       " 'degrees',\n",
       " 'conversion',\n",
       " 'shores',\n",
       " 'workable',\n",
       " 'out',\n",
       " 'greatly',\n",
       " 'suffered',\n",
       " 'd',\n",
       " 'income',\n",
       " 'procedure',\n",
       " 'intrinsically',\n",
       " 'advisers',\n",
       " 'a',\n",
       " 'stringent',\n",
       " 'oversight',\n",
       " ...}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_en_diff = get_diff_words(text_en)\n",
    "text_en_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "YAYCeDyieBlb",
    "outputId": "c1e7a495-12be-4444-f390-8b8a4dc030ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'r,e,s,u,m,p,t,i,o,n, ,o,f, ,t,h,e, ,s,e,s,s,i,o,n, ,i, ,d,e'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@d2l.add_to_class(ParallelCorpus)\n",
    "def _tokenize(self, text):\n",
    "    return list(text)\n",
    "\n",
    "tokens = data._tokenize(text_en)\n",
    "','.join(tokens[:30])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "id": "rIOqd6VVxnio"
   },
   "outputs": [],
   "source": [
    "class Vocab:\n",
    "    \"\"\"Vocabulary for text.\"\"\"\n",
    "    def __init__(self, tokens=[], min_freq=0, reserved_tokens=[]):\n",
    "        # Flatten a 2D list if needed\n",
    "        if tokens and isinstance(tokens[0], list):\n",
    "            tokens = [token for line in tokens for token in line]\n",
    "        # Count token frequencies\n",
    "        counter = collections.Counter(tokens)\n",
    "        self.token_freqs = sorted(counter.items(), key=lambda x: x[1],\n",
    "                                  reverse=True)\n",
    "        # The list of unique tokens\n",
    "        self.idx_to_token = list(sorted(set(['<unk>'] + reserved_tokens + [\n",
    "            token for token, freq in self.token_freqs if freq >= min_freq])))\n",
    "        self.token_to_idx = {token: idx\n",
    "                             for idx, token in enumerate(self.idx_to_token)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "\n",
    "    def __getitem__(self, tokens):\n",
    "        if not isinstance(tokens, (list, tuple)):\n",
    "            return self.token_to_idx.get(tokens, self.unk)\n",
    "        return [self.__getitem__(token) for token in tokens]\n",
    "\n",
    "    def to_tokens(self, indices):\n",
    "        if hasattr(indices, '__len__') and len(indices) > 1:\n",
    "            return [self.idx_to_token[int(index)] for index in indices]\n",
    "        return self.idx_to_token[indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # Index for the unknown token\n",
    "        return self.token_to_idx['<unk>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tSGXHxmixrpU",
    "outputId": "e86b1610-92bb-4058-d5b3-7ad0693f4c12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices: [29, 16, 30, 32, 24, 27, 31, 20, 26, 25, 0, 26, 17, 0, 31, 19, 16, 0, 30, 16]\n",
      "words: ['r', 'e', 's', 'u', 'm', 'p', 't', 'i', 'o', 'n', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 's', 'e']\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocab(tokens)\n",
    "indices = vocab[tokens[:20]]\n",
    "print('indices:', indices)\n",
    "print('words:', vocab.to_tokens(indices))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Definindo o Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "id": "xz4GCrAGyIFJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(289559458, 180)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@d2l.add_to_class(ParallelCorpus)\n",
    "def build(self, raw_text, vocab=None):\n",
    "    tokens = self._tokenize(self._preprocess(raw_text))\n",
    "    if vocab is None: vocab = Vocab(tokens)\n",
    "    corpus = [vocab[token] for token in tokens]\n",
    "    return corpus, vocab\n",
    "\n",
    "corpus, vocab = data.build(raw_text_en)\n",
    "len(corpus), len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eh_Q_15c0GHO",
    "outputId": "ec96c8b5-7bad-46ae-ab8e-ba8a0a0464cd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 734),\n",
       " ('of', 360),\n",
       " ('to', 343),\n",
       " ('and', 229),\n",
       " ('in', 228),\n",
       " ('that', 185),\n",
       " ('is', 177),\n",
       " ('a', 175),\n",
       " ('this', 160),\n",
       " ('i', 144)]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = text_en.split()\n",
    "vocab = Vocab(words)\n",
    "vocab.token_freqs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('of--the', 112),\n",
       " ('the--commission', 61),\n",
       " ('in--the', 57),\n",
       " ('on--the', 53),\n",
       " ('i--would', 47),\n",
       " ('like--to', 44),\n",
       " ('for--the', 43),\n",
       " ('to--the', 39),\n",
       " ('that--the', 38),\n",
       " ('it--is', 31)]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigram_tokens = ['--'.join(pair) for pair in zip(words[:-1], words[1:])]\n",
    "bigram_vocab = Vocab(bigram_tokens)\n",
    "bigram_vocab.token_freqs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i--would--like', 23),\n",
       " ('would--like--to', 21),\n",
       " ('of--dangerous--goods', 19),\n",
       " ('the--transport--of', 15),\n",
       " ('transport--of--dangerous', 15),\n",
       " ('madam--president--i', 13),\n",
       " ('that--the--commission', 13),\n",
       " ('president--i--would', 12),\n",
       " ('the--committee--on', 12),\n",
       " ('i--should--like', 11)]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigram_tokens = ['--'.join(triple) for triple in zip(\n",
    "    words[:-2], words[1:-1], words[2:])]\n",
    "trigram_vocab = Vocab(trigram_tokens)\n",
    "trigram_vocab.token_freqs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E1v9mrSkarX1",
    "outputId": "57a90cb1-13e7-4b74-fdf6-cbc28e3be4ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9956 9954\n"
     ]
    }
   ],
   "source": [
    "source_sentences = text_en.split()\n",
    "target_sentences = text_pt.split()\n",
    "\n",
    "print(len(source_sentences), len(target_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "id": "_exWZNlzZuzY"
   },
   "outputs": [],
   "source": [
    "from nltk import AlignedSent\n",
    "\n",
    "bitext = []\n",
    "bitext.append(AlignedSent(source_sentences, target_sentences))\n",
    "ibm_model = IBMModel1(bitext, 5)  # 5 iterations for training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codificador-Decodificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "id": "hw2YV9RSvg4i"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class Seq2SeqEncoder(d2l.Encoder):  #@save\n",
    "    \"\"\"The RNN encoder for sequence-to-sequence learning.\"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0):\n",
    "        super().__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = d2l.GRU(num_hiddens, num_layers, dropout)\n",
    "\n",
    "    def call(self, X, *args):\n",
    "        # X shape: (batch_size, num_steps)\n",
    "        embs = self.embedding(tf.transpose(X))\n",
    "        # embs shape: (num_steps, batch_size, embed_size)\n",
    "        outputs, state = self.rnn(embs)\n",
    "        # outputs shape: (num_steps, batch_size, num_hiddens)\n",
    "        # state shape: (num_layers, batch_size, num_hiddens)\n",
    "        return outputs, state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size, embed_size, num_hiddens, num_layers = 10, 8, 16, 2\n",
    "batch_size, num_steps = 4, 9\n",
    "encoder = Seq2SeqEncoder(vocab_size, embed_size, num_hiddens, num_layers)\n",
    "X = tf.zeros((batch_size, num_steps))\n",
    "enc_outputs, enc_state = encoder(X)\n",
    "d2l.check_shape(enc_outputs, (num_steps, batch_size, num_hiddens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "d2l.check_len(enc_state, num_layers)\n",
    "d2l.check_shape(enc_state[0], (batch_size, num_hiddens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDecoder(d2l.Decoder):\n",
    "    \"\"\"The RNN decoder for sequence to sequence learning.\"\"\"\n",
    "    def __init__(self, vocab_size, embed_size, num_hiddens, num_layers,\n",
    "                 dropout=0):\n",
    "        super().__init__()\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embed_size)\n",
    "        self.rnn = d2l.GRU(num_hiddens, num_layers, dropout)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def init_state(self, enc_all_outputs, *args):\n",
    "        return enc_all_outputs\n",
    "\n",
    "    def call(self, X, state):\n",
    "        # X shape: (batch_size, num_steps)\n",
    "        # embs shape: (num_steps, batch_size, embed_size)\n",
    "        embs = self.embedding(tf.transpose(X))\n",
    "        enc_output, hidden_state = state\n",
    "        # context shape: (batch_size, num_hiddens)\n",
    "        context = enc_output[-1]\n",
    "        # Broadcast context to (num_steps, batch_size, num_hiddens)\n",
    "        context = tf.tile(tf.expand_dims(context, 0), (embs.shape[0], 1, 1))\n",
    "        # Concat at the feature dimension\n",
    "        embs_and_context = tf.concat((embs, context), -1)\n",
    "        outputs, hidden_state = self.rnn(embs_and_context, hidden_state)\n",
    "        outputs = tf.transpose(self.dense(outputs), (1, 0, 2))\n",
    "        # outputs shape: (batch_size, num_steps, vocab_size)\n",
    "        # hidden_state shape: (num_layers, batch_size, num_hiddens)\n",
    "        return outputs, [enc_output, hidden_state]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Seq2SeqDecoder(vocab_size, embed_size, num_hiddens, num_layers)\n",
    "state = decoder.init_state(encoder(X))\n",
    "dec_outputs, state = decoder(X, state)\n",
    "d2l.check_shape(dec_outputs, (batch_size, num_steps, vocab_size))\n",
    "d2l.check_len(state[1], num_layers)\n",
    "d2l.check_shape(state[1][0], (batch_size, num_hiddens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(d2l.EncoderDecoder):  #@save\n",
    "    \"\"\"The RNN encoder--decoder for sequence to sequence learning.\"\"\"\n",
    "    def __init__(self, encoder, decoder, tgt_pad, lr):\n",
    "        super().__init__(encoder, decoder)\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        Y_hat = self(*batch[:-1])\n",
    "        self.plot('loss', self.loss(Y_hat, batch[-1]), train=False)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Adam optimizer is used here\n",
    "        return tf.keras.optimizers.Adam(learning_rate=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(Seq2Seq)\n",
    "def loss(self, Y_hat, Y):\n",
    "    l = super(Seq2Seq, self).loss(Y_hat, Y, averaged=False)\n",
    "    mask = tf.cast(tf.reshape(Y, -1) != self.tgt_pad, tf.float32)\n",
    "    return tf.reduce_sum(l * mask) / tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(ParallelCorpus)\n",
    "def get_dataloader(self, train):\n",
    "    return d2l.load_data_nmt(batch_size=2, num_steps=10, num_examples=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'_BatchDataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[187], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     model \u001b[38;5;241m=\u001b[39m Seq2Seq(encoder, decoder, tgt_pad\u001b[38;5;241m=\u001b[39mvocab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<pad>\u001b[39m\u001b[38;5;124m'\u001b[39m], lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.005\u001b[39m)\n\u001b[1;32m      8\u001b[0m trainer \u001b[38;5;241m=\u001b[39m d2l\u001b[38;5;241m.\u001b[39mTrainer(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, gradient_clip_val\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/NoIA-3/lib/python3.9/site-packages/d2l/tensorflow.py:271\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, data)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_batch_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs):\n\u001b[0;32m--> 271\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/NoIA-3/lib/python3.9/site-packages/d2l/tensorflow.py:285\u001b[0m, in \u001b[0;36mTrainer.fit_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_dataloader:\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[0;32m--> 285\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprepare_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m     grads \u001b[38;5;241m=\u001b[39m tape\u001b[38;5;241m.\u001b[39mgradient(loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mtrainable_variables)\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgradient_clip_val \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/NoIA-3/lib/python3.9/site-packages/d2l/tensorflow.py:205\u001b[0m, in \u001b[0;36mModule.training_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtraining_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m--> 205\u001b[0m     l \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss(\u001b[38;5;28mself\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m), batch[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, l, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m l\n",
      "\u001b[0;31mTypeError\u001b[0m: '_BatchDataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "embed_size, num_hiddens, num_layers, dropout = 256, 256, 2, 0.2\n",
    "with d2l.try_gpu():\n",
    "    encoder = Seq2SeqEncoder(\n",
    "        len(source_sentences), embed_size, num_hiddens, num_layers, dropout)\n",
    "    decoder = Seq2SeqDecoder(\n",
    "        len(target_sentences), embed_size, num_hiddens, num_layers, dropout)\n",
    "    model = Seq2Seq(encoder, decoder, tgt_pad=vocab['<pad>'], lr=0.005)\n",
    "trainer = d2l.Trainer(max_epochs=30, gradient_clip_val=1)\n",
    "\n",
    "trainer.fit(model, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "@d2l.add_to_class(d2l.EncoderDecoder)  #@save\n",
    "def predict_step(self, batch, device, num_steps,\n",
    "                 save_attention_weights=False):\n",
    "    src, tgt, src_valid_len, _ = batch\n",
    "    enc_all_outputs = self.encoder(src, src_valid_len, training=False)\n",
    "    dec_state = self.decoder.init_state(enc_all_outputs, src_valid_len)\n",
    "    outputs, attention_weights = [tf.expand_dims(tgt[:, 0], 1), ], []\n",
    "    for _ in range(num_steps):\n",
    "        Y, dec_state = self.decoder(outputs[-1], dec_state, training=False)\n",
    "        outputs.append(tf.argmax(Y, 2))\n",
    "        # Save attention weights (to be covered later)\n",
    "        if save_attention_weights:\n",
    "            attention_weights.append(self.decoder.attention_weights)\n",
    "    return tf.concat(outputs[1:], 1), attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engs = ['go .', 'i lost .', 'he\\'s calm .', 'i\\'m home .']\n",
    "ports = ['vai .', 'eu perdi .', 'ele está calmo .', 'estou em casa .']\n",
    "preds, _ = model.predict_step(\n",
    "    data.build(engs, ports), d2l.try_gpu(), data.num_steps)\n",
    "for en, pt, p in zip(engs, ports, preds):\n",
    "    translation = []\n",
    "    for token in vocab.to_tokens(p):\n",
    "        if token == '<eos>':\n",
    "            break\n",
    "        translation.append(token)\n",
    "    print(f'{en} => {translation}, bleu,'\n",
    "          f'{sentence_bleu([pt.split()], translation, weights=(1, 0, 0, 0))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "NoIA-3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
